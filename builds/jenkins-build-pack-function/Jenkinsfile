#!groovy

import groovy.json.JsonOutput
import groovy.json.JsonSlurper
import groovy.transform.Field

// To be replaced as @Field def repo_credential_id = "value" for repo_credential_id, repo_base and repo_core

@Field def repo_credential_id
@Field def aws_credential_id
@Field def region
@Field def instance_prefix
@Field def repo_base
@Field def repo_core
@Field def scm_type

@Field def configModule
@Field def configLoader
@Field def scmModule
@Field def serviceConfigdata
@Field def awsAPIGatewayModule
@Field def events
@Field def lambdaEvents
@Field def serviceMetadataLoader
@Field def utilModule
@Field def environmentDeploymentMetadata
@Field def sonarModule
@Field def azureDeployer

@Field def auth_token = ''
@Field def config
@Field def g_base_url = ''
@Field def g_svc_admin_cred_ID = 'SVC_ADMIN'
@Field def current_environment = ''
@Field def isLambdaUpdateRequired = false
@Field def environment_logical_id

node() {
  try {
  def jazzBuildModuleURL = getBuildModuleUrl()
  loadBuildModules(jazzBuildModuleURL)

	echo "Build triggered via branch: " + params.scm_branch + " with params: " + params
  def _event = ""

  def requestId = params.request_id
  def branch = params.scm_branch
  def domain = params.domain
  def repo_name = domain + "_" + params.service_name
  
  def gitCommitOwner
  def gitCommitHash
  def context_map
  def accountDetails
  def accountDetailsPrimary
  
  stage('Checkout code base') {

    sh 'rm -rf ' + repo_name
    sh 'mkdir ' + repo_name
    sh 'pwd'

    def repocloneUrl
    if (domain == "jazz") {
      repocloneUrl = scmModule.getCoreRepoCloneUrl(repo_name)
    } else {
      repocloneUrl = scmModule.getRepoCloneUrl(repo_name)
    }

    dir(repo_name) {
      checkout([$class: 'GitSCM', branches: [
        [name: '*/' + params.scm_branch]
      ], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [
          [credentialsId: repo_credential_id, url: repocloneUrl]
        ]])
    }

    def configObj = dir(repo_name) {
      LoadConfiguration()
    }

    if (configObj.service_id) {
      config = serviceMetadataLoader.loadServiceMetadata(configObj.service_id)
    } else {
      error "Service Id is not available."
    }
  }
  if(config['provider'] == 'aws'){
    accountDetails = utilModule.getAccountInfo(config);
  }
  accountDetailsPrimary = utilModule.getAccountInfoPrimary();

  if (!config) {
    error "Failed to fetch service metadata from catalog"
  }

  if(!config.region) {
    config.region = configLoader.AWS.DEFAULTS.REGION
  }

  if(!config.accountId) {
    config.accountId = configLoader.AWS.DEFAULTS.ACCOUNTID
  }

  if(!config.provider) {
    config.provider = configLoader.JAZZ.DEFAULTS.PROVIDER
  }

  def coreDomain = "jazz";
  def jazz_prod_api_id = awsAPIGatewayModule.getApigatewayInfoCore('PROD', coreDomain, accountDetailsPrimary);
  g_base_url = "https://${jazz_prod_api_id}.execute-api.${configLoader.AWS.DEFAULTS.REGION}.amazonaws.com/prod"
  if(domain != "jazz"){
    auth_token = setCredentials()
  }

  dir(repo_name) {
    scmModule.setServiceConfig(config)
    lambdaEvents.setServiceConfig(config)
    def envApi = "${g_base_url}/jazz/environments"
    environmentDeploymentMetadata.initialize(config, configLoader, scmModule, branch, env.BUILD_URL, env.BUILD_ID, envApi, auth_token)
    gitCommitHash = scmModule.getRepoCommitHash()
    gitCommitOwner = scmModule.getRepoCommitterInfo(gitCommitHash)
    context_map = [created_by: config['created_by'], deployed_by: gitCommitOwner]
    environment_logical_id = '';

    if (branch == 'master') {
      current_environment = 'prod'
      environment_logical_id = 'prod';
    } else {
      current_environment = 'dev'
      environment_logical_id = environmentDeploymentMetadata.getEnvironmentLogicalId();
    }

    if (!environment_logical_id && config['domain'] != 'jazz') {
      error "The environment has not been created yet and its missing the environment id"
    }
  }
  if (!events) {
    error "Can't load events module"
  } //Fail here
  def eventsApi = "${g_base_url}/jazz/events"
  events.initialize(configLoader, config, "SERVICE_DEPLOYMENT", branch, environment_logical_id, eventsApi)

  def runtime = config['providerRuntime']
  def service = config['service']
  def isScheduleEnabled = isEnabled(config, "eventScheduleRate")
  def isStreamEnabled = isEnabled(config, "event_source_kinesis")
  def isDynamoDbEnabled = isEnabled(config, "event_source_dynamodb")
  def isS3EventEnabled = isEnabled(config, "event_source_s3")
  def isSQSEventEnabled = isEnabled(config, "event_source_sqs")
  def isEc2EventEnabled = isEnabled(config, "event_source_ec2")
  def isCosmoDbEnabled = isEnabled(config, "event_source_cosmosdb")
  def isEventHubEnabled = isEnabled(config, "event_source_eventhub")
  def isStorageEnabled = isEnabled(config, "event_source_storageaccount")
  def isServiceBusQueueEnabled = isEnabled(config, "event_source_servicebusqueue")
  def isEventSchdld = false
  def internalAccess = config['require_internal_access']
  domain = config['domain']

  def servicePlatform = config['provider']
  def roleARN;
  if(config['provider'] == 'aws'){
    roleARN = accountDetails.IAM.PLATFORMSERVICES_ROLEID.replaceAll("/", "\\\\/")
  } 

  sonarModule.initialize(configLoader, config, branch)
  stackName = "${configLoader.INSTANCE_PREFIX}-${config['domain']}-${config['service']}-${environment_logical_id}"

  if (isScheduleEnabled || isEc2EventEnabled || isS3EventEnabled || isStreamEnabled || isDynamoDbEnabled || isSQSEventEnabled){
    isEventSchdld = true
  }

  echo "requestId: $requestId"
  if (requestId != "none" && requestId != null && !utilModule.isReplayedBuild()) {
    requestId = requestId
    events.setRequestId(requestId)
    environmentDeploymentMetadata.setRequestId(requestId)
  } else {
    requestId = utilModule.generateRequestId()
    events.setRequestId(requestId)
    environmentDeploymentMetadata.setRequestId(requestId)
    events.sendStartedEvent('CREATE_DEPLOYMENT', 'Function deployment started', environmentDeploymentMetadata.generateDeploymentMap("started", environment_logical_id, gitCommitHash), environment_logical_id)
  }


  dir(repo_name) {
    if (servicePlatform == "aws") {
      loadServerlessConfig(runtime, isEventSchdld, isScheduleEnabled, isEc2EventEnabled, isS3EventEnabled, isSQSEventEnabled, isStreamEnabled, isDynamoDbEnabled)
    }
    if (domain == "jazz") {
      stage('Update Service Template') {
        echo "Inside Update service template"
        try {
          updatePlatformServiceTemplate(config, roleARN, current_environment, repo_name)
        } catch (error) {
          error "Error occured while updating service template."
        }
      }
    }
    stage('Pre-Build Validation') {
      events.sendStartedEvent('VALIDATE_PRE_BUILD_CONF', 'pre-build validation started', context_map, environment_logical_id)
      try {
        send_status_email('STARTED', '')
        validateDeploymentConfigurations(config)
      } catch (ex) {
        send_status_email('FAILED', '')
        events.sendFailureEvent('VALIDATE_PRE_BUILD_CONF', ex.getMessage(), context_map, environment_logical_id)
        events.sendFailureEvent('UPDATE_DEPLOYMENT', ex.getMessage(), environmentDeploymentMetadata.generateDeploymentMap("failed", environment_logical_id, gitCommitHash), environment_logical_id)
        error ex.getMessage()
      }
      events.sendCompletedEvent('VALIDATE_PRE_BUILD_CONF', 'pre-build validation completed', context_map, environment_logical_id)
    }

    if (config['domain'] != 'jazz' && configLoader.CODE_QUALITY.SONAR.ENABLE_SONAR == "true") {
      stage('Code Quality Check') {
        events.sendStartedEvent('CODE_QUALITY_CHECK', 'code quality check starts', context_map, environment_logical_id)
        try {
          runValidation(runtime)
          sonarModule.doAnalysis()
        } catch (ex) {
          events.sendFailureEvent('CODE_QUALITY_CHECK', ex.getMessage(), context_map, environment_logical_id)
          events.sendFailureEvent('UPDATE_DEPLOYMENT', ex.getMessage(), environmentDeploymentMetadata.generateDeploymentMap("failed", environment_logical_id, gitCommitHash), environment_logical_id)
          error ex.getMessage()
        }
        events.sendCompletedEvent('CODE_QUALITY_CHECK', 'code quality check completed', context_map, environment_logical_id)
      }
    }

    stage('Build') {
      events.sendStartedEvent('BUILD', 'build starts', context_map, environment_logical_id)
      try {
        buildFunction(runtime, repo_name)
      } catch (ex) {
        events.sendFailureEvent('BUILD', ex.getMessage(), context_map, environment_logical_id)
        events.sendFailureEvent('UPDATE_DEPLOYMENT', ex.getMessage(), environmentDeploymentMetadata.generateDeploymentMap("failed", environment_logical_id, gitCommitHash), environment_logical_id)
        error ex.getMessage()
      }
      events.sendCompletedEvent('BUILD', 'build completed', context_map, environment_logical_id)
    }

    def env_key
    if (branch == "master") {
      env_key = "PROD"
    } else {
      env_key = "DEV"
    }
    stage("Deployment to ${env_key} environment") {
      events.sendStartedEvent('DEPLOY_TO_AWS', 'Deployment started to staging AWS environment', context_map, environment_logical_id)
      events.sendStartedEvent('UPDATE_ENVIRONMENT', "Environment status update event for ${env_key} deployment", environmentDeploymentMetadata.generateEnvironmentMap("deployment_started", environment_logical_id, null), environment_logical_id)

      echo "starts Deployment to ${env_key} Env"
      def lambdaARN = null
      environmentDeploymentMetadata.setEnvironmentEndpoint(lambdaARN)
      events.sendStartedEvent('UPDATE_ENVIRONMENT', "Environment status update event for ${env_key} deployment", environmentDeploymentMetadata.generateEnvironmentMap("deployment_started", environment_logical_id, null), environment_logical_id)
      
      def logicalId
      def credsId = null
      if (servicePlatform == 'azure') {
        timestamps {
          if (environment_logical_id == "prod") {
            logicalId = config['service_id'].substring(0, 7) + environment_logical_id
          } else {
            logicalId = environment_logical_id.split('-')[0] //13 + 10
          }
          def sgName = "${configLoader.INSTANCE_PREFIX}${logicalId}"
          def storageName = sgName.replaceAll("[^a-zA-Z0-9]", "")

          def serviceInfo = [
            'stackName'         : stackName,
            'storageAccountName': storageName,
            "repoCredentialId"  : repo_credential_id,
            'envId'             : environment_logical_id,
            'serviceCatalog'    : config,
            'isScheduleEnabled' : isScheduleEnabled,
            'isStreamEnabled'   : isEventHubEnabled,
            'isQueueEnabled'    : isServiceBusQueueEnabled,
            'isDbEnabled'       : isCosmoDbEnabled,
            'isStorageEnabled'  : isStorageEnabled
          ]
          try {
            def endpoint = azureDeployer.createFunction(serviceInfo)
            environmentDeploymentMetadata.setEnvironmentEndpoint(endpoint)
            def svc_response = "Your service endpoint: $endpoint"
            events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], endpoint, 'endpoint_url', config), environment_logical_id)
            sendFinalCompleteEvent(env_key, servicePlatform, environment_logical_id, config, gitCommitHash, gitCommitOwner, svc_response)
          } catch (ex) {
            handleFail(ex, context_map, environment_logical_id, config, gitCommitHash)
          }
        }
        return
      }
      else if (servicePlatform == 'aws') {
        withCredentials([
          [$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId: accountDetails.CREDENTIAL_ID, secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']]) {
          try {
            // initialize aws credentials
            def randomString = utilModule.generateRequestId();
            credsId = "jazz-${randomString}";
            sh "aws configure set profile.${credsId}.region ${service_config.region}"
            sh "aws configure set profile.${credsId}.aws_access_key_id $AWS_ACCESS_KEY_ID"
            sh "aws configure set profile.${credsId}.aws_secret_access_key $AWS_SECRET_ACCESS_KEY"

            loadServerlessConfig(runtime, isEventSchdld, isScheduleEnabled, isEc2EventEnabled, isS3EventEnabled, isSQSEventEnabled, isStreamEnabled, isDynamoDbEnabled)

            // Generate serverless yml file with domain added in function name
            echo "Generate deployment env with domain"

            if (isScheduleEnabled) {
              def eventsArns = getEventsArn(config, environment_logical_id, credsId)
              for (def i = 0; i < eventsArns.size(); i++) {
                def arn = eventsArns[i]
                events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], arn, "cloudwatch_event", config), environment_logical_id);
              }
            }

            writeServerlessFile(config, environment_logical_id, accountDetails)

            def envBucketKey = "${env_key}${configLoader.JAZZ.PLATFORM.AWS.S3.BUCKET_NAME_SUFFIX}"
            echoServerlessFile()
            def deployOutput = servelessDeploy(environment_logical_id, envBucketKey, credsId, env_key, accountDetails)

            if (deployOutput != 'success') {
              if (config['event_source_s3']) {
                handleS3BucketError(deployOutput, config['event_source_s3'], environment_logical_id, envBucketKey, isEventSchdld, credsId, accountDetails, config)
              } else if (config['event_source_sqs']) {
                handleSqsError(deployOutput, config, environment_logical_id, envBucketKey, credsId, accountDetails)
              } else if (config['event_source_kinesis']) {
                handleKinesisStreamError(deployOutput, config['event_source_kinesis'], environment_logical_id, envBucketKey, credsId, accountDetails, config)
              } else if (config['event_source_dynamodb']) {
                handleDynamoDbStreamError(deployOutput, config, environment_logical_id, envBucketKey, credsId, accountDetails)
              } else {
                handleDeploymentErrors(deployOutput, envBucketKey, environment_logical_id, credsId, accountDetails, config)
              }
            } else {
              if (config['event_source_s3']) {
                def bucket_arn = "arn:aws:s3:::${config['event_source_s3']}"
                def s3_bucket_arn = lambdaEvents.getEventResourceNamePerEnvironment(bucket_arn, environment_logical_id, "-")
                events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], s3_bucket_arn, "s3", config), environment_logical_id);
              } else if (config['event_source_sqs']) {
                def event_source_sqs_arn = lambdaEvents.getEventResourceNamePerEnvironment(config['event_source_sqs'], environment_logical_id, "_")
                events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], event_source_sqs_arn, "sqs", config), environment_logical_id);
              } else if (config['event_source_kinesis']) {
                def event_source_kinesis_stream_arn = lambdaEvents.getEventResourceNamePerEnvironment(config['event_source_kinesis'], environment_logical_id, "_")
                events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], event_source_kinesis_stream_arn, "kinesis_stream", config), environment_logical_id);
              } else if (config['event_source_dynamodb']) {
                def dynamodbTableName = lambdaEvents.splitAndGetResourceName(config['event_source_dynamodb'], environment_logical_id)
                def stream_details = lambdaEvents.getDynamoDbStreamDetails(dynamodbTableName)
                def event_source_dynamodb_arn = lambdaEvents.getEventResourceNamePerEnvironment(config['event_source_dynamodb'], environment_logical_id, "_")
                events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], event_source_dynamodb_arn, "dynamodb", config), environment_logical_id);
                events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], stream_details.StreamArn, "dynamodb_stream", config), environment_logical_id);
              }
            }

            def function_arn = getLambdaARN(stackName, credsId);
            lambdaARN = function_arn.split(":(?!.*:.*)")[0]
            events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], lambdaARN, "lambda", config), environment_logical_id);

            echo "lambdaARN: ${lambdaARN}"

            if (isLambdaUpdateRequired) {
              def event_source_s3 = lambdaEvents.getEventResourceNamePerEnvironment(config['event_source_s3'], environment_logical_id, "-")
              lambdaEvents.updateLambdaPermissionAndNotification(lambdaARN, event_source_s3, config['event_action_s3'], credsId)
            }

            if (config['event_source_dynamodb'] || config['event_source_sqs'] || config['event_source_kinesis'] || config['event_source_s3']) {
              def role_name = "${configLoader.INSTANCE_PREFIX}-${config['domain']}-${config['service']}-${environment_logical_id}"
              def role_arn = lambdaEvents.getRoleArn(role_name, credsId)
              events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], role_arn, "iam_role", config), environment_logical_id);
            }

            if (domain != "jazz") {
              createSubscriptionFilters(config, env_key, credsId, accountDetails);
            }

            if(!accountDetails.PRIMARY){
              def primaryAccountData = utilModule.getAccountInfoPrimary();
              def primaryAccountValue = primaryAccountData.ACCOUNTID;
              def lambdaFnNameValue = "${configLoader.INSTANCE_PREFIX}_${config['domain']}_${config['service']}_${environment_logical_id}"

              addPermission(lambdaFnNameValue, primaryAccountValue, credsId, config);
            }

            if (domain == "jazz") {
              serviceConfigdata.setLogStreamPermission(config)
              serviceConfigdata.setKinesisStream(config)
            }

          } catch (ex) {
            handleFail(ex, context_map, environment_logical_id, config, gitCommitHash)
          } finally {
            // reset Credentials
            resetCredentials(credsId)
          }
          environmentDeploymentMetadata.setEnvironmentEndpoint(lambdaARN)
          def svc_response = echoServiceInfo(environment_logical_id)
          sendFinalCompleteEvent(env_key, servicePlatform, environment_logical_id, config, gitCommitHash, gitCommitOwner, svc_response)
        } //end of withCredentials
      }
    } //end of deployment to an environment
  }
  } catch (err) {
   throw err
  } finally {
   deleteDir()
  }
}


private void sendFinalCompleteEvent(env_key, servicePlatform, environment_logical_id, config, gitCommitHash, gitCommitOwner, svc_response) {
  def serviceContext = [created_by: config['created_by'], deployed_by: gitCommitOwner]
  echo "==============================================================================================="
  echo svc_response
  echo "==============================================================================================="
  send_status_email('COMPLETED', svc_response)
  events.sendCompletedEvent('UPDATE_ENVIRONMENT', 'Environment update event for deployment completion', environmentDeploymentMetadata.generateEnvironmentMap("deployment_completed", environment_logical_id, null), environment_logical_id)
  events.sendCompletedEvent('UPDATE_DEPLOYMENT', "Deployment completion Event for ${env_key} deployment", environmentDeploymentMetadata.generateDeploymentMap("successful", environment_logical_id, gitCommitHash), environment_logical_id)
  // TODO: Replace DEPLOY_TO_AWS => DEPLOY_TO_CLOUD??
  events.sendCompletedEvent('DEPLOY_TO_AWS', "Successfully deployed services to ${servicePlatform}", serviceContext, environment_logical_id)
}

def handleFail(ex, context_map, environment_logical_id, config, gitCommitHash) {
  echo "error: $ex"
  send_status_email('FAILED', '')
  events.sendFailureEvent('UPDATE_ENVIRONMENT', ex.getMessage(), environmentDeploymentMetadata.generateEnvironmentMap("deployment_failed", environment_logical_id, null), environment_logical_id)
  events.sendFailureEvent('UPDATE_DEPLOYMENT', ex.getMessage(), environmentDeploymentMetadata.generateDeploymentMap("failed", environment_logical_id, gitCommitHash), environment_logical_id)
  // TODO: Replace DEPLOY_TO_AWS => DEPLOY_TO_CLOUD??
  events.sendFailureEvent('DEPLOY_TO_AWS', ex.getMessage(), context_map, environment_logical_id)
  error ex.getMessage()
}

def addPermission(functionName, primaryAccountValue, credsId, service_config){
  try {
		sh "aws lambda remove-permission --function-name ${functionName} --region ${service_config.region} --statement-id ${functionName}_invoke --profile ${credsId}"
	} catch(Exception ex) {
		// ignore if the policy is not there
	}
  /* Adding permission to invoke the function created in secondary account*/
  sh "aws lambda add-permission --function-name ${functionName} --region ${service_config.region} --statement-id ${functionName}_invoke --action 'lambda:InvokeFunction' --principal ${primaryAccountValue} --profile ${credsId}"
}

def handleS3BucketError(deployOutput, s3BucketName, environment_logical_id, envBucketKey, isEventSchdld, credsId, accountDetails, config) {
  def s3BucketErrString = "CloudFormation - CREATE_FAILED - AWS::S3::Bucket - "
  s3BucketName = lambdaEvents.getEventResourceNamePerEnvironment(s3BucketName, environment_logical_id, "-")
  if (deployOutput.contains(s3BucketErrString)) {
    if (lambdaEvents.checkS3BucketExists(s3BucketName, credsId)) {
      isLambdaUpdateRequired = true
      lambdaEvents.removeS3EventsFromServerless(isEventSchdld)
      deleteAndRedeployService(environment_logical_id, envBucketKey, accountDetails, config)
    } else {
      error "Error occured while accessing the s3 bucket"
    }
  } else {
    echo "Exception occured while serverless deployment to ${environment_logical_id} environment : $deployOutput"
    error "Exception occured while serverless deployment to ${environment_logical_id} environment"
  }
}

def handleSqsError(deployOutput, service_config, environment_logical_id, envBucketKey, credsId, accountDetails) {
  def event_source_sqs_arn = service_config['event_source_sqs']
  def sqsErrString = "CloudFormation - CREATE_FAILED - AWS::SQS::Queue - "
  if (deployOutput.contains(sqsErrString)) {
    def event_source_sqs = lambdaEvents.getSqsQueueName(event_source_sqs_arn, environment_logical_id)
    event_source_sqs_arn = lambdaEvents.getEventResourceNamePerEnvironment(event_source_sqs_arn, environment_logical_id, "_")
    def lambda_arn = "arn:aws:lambda:${config['region']}:${config['accountId']}:function:${configLoader.INSTANCE_PREFIX}_${service_config['domain']}_${service_config['service']}_${environment_logical_id}"
    if (lambdaEvents.checkSqsQueueExists(event_source_sqs, credsId)) {
      if (lambdaEvents.checkIfDifferentFunctionTriggerAttached(event_source_sqs_arn, lambda_arn, credsId)) {
        error "Queue contains a different function trigger already. Please remove the existing function trigger and try again."
      }
      lambdaEvents.updateSqsResourceServerless()
      deleteAndRedeployService(environment_logical_id, envBucketKey, accountDetails, service_config)
    } else {
      error "Error occured while accessing the SQS queue"
    }
  } else {
    echo "Exception occured while serverless deployment to ${environment_logical_id} environment : $deployOutput"
    error "Exception occured while serverless deployment to ${environment_logical_id} environment"
  }
}

def handleKinesisStreamError(deployOutput, event_source_kinesis_stream_arn, environment_logical_id, envBucketKey, credsId, accountDetails, service_config) {
  def kinesisStreamErrString = "CloudFormation - CREATE_FAILED - AWS::Kinesis::Stream - "
  def event_source_kinesis = lambdaEvents.splitAndGetResourceName(event_source_kinesis_stream_arn, environment_logical_id)
  event_source_kinesis_stream_arn = lambdaEvents.getEventResourceNamePerEnvironment(event_source_kinesis_stream_arn, environment_logical_id, "_")
  def lambda_arn = "arn:aws:lambda:${config['region']}:${config['accountId']}:function:${configLoader.INSTANCE_PREFIX}_${service_config['domain']}_${service_config['service']}_${environment_logical_id}"
  if (deployOutput.contains(kinesisStreamErrString)) {
    if (lambdaEvents.checkKinesisStreamExists(event_source_kinesis, credsId)) {
      if (lambdaEvents.checkIfDifferentFunctionTriggerAttached(event_source_kinesis_stream_arn, lambda_arn, credsId)) {
        error "Kinesis stream contains a different function trigger already. Please remove the existing function trigger and try again."
      }
      lambdaEvents.updateKinesisResourceServerless(event_source_kinesis_stream_arn)
      deleteAndRedeployService(environment_logical_id, envBucketKey, accountDetails, service_config)
    } else {
      error "Error occured while accessing the Kinesis stream"
    }
  } else {
    echo "Exception occured while serverless deployment to ${environment_logical_id} environment : $deployOutput"
    error "Exception occured while serverless deployment to ${environment_logical_id} environment"
  }
}

def handleDynamoDbStreamError(deployOutput, service_config, environment_logical_id, envBucketKey, credsId, accountDetails) {
  def dynamodbTableErrString = "CloudFormation - CREATE_FAILED - AWS::DynamoDB::Table - "
  def event_source_dynamodb_table_arn = service_config['event_source_dynamodb']
  def event_source_dynamodb = lambdaEvents.splitAndGetResourceName(event_source_dynamodb_table_arn, environment_logical_id)
  event_source_dynamodb_table_arn = lambdaEvents.getEventResourceNamePerEnvironment(event_source_dynamodb_table_arn, environment_logical_id, "_")
  def lambda_arn = "arn:aws:lambda:${config['region']}:${config['accountId']}:function:${configLoader.INSTANCE_PREFIX}_${service_config['domain']}_${service_config['service']}_${environment_logical_id}"
  if (deployOutput.contains(dynamodbTableErrString)) {
    if (lambdaEvents.checkDynamoDbTableExists(event_source_dynamodb)) {
      def stream_details = lambdaEvents.getDynamoDbStreamDetails(event_source_dynamodb)
      if (!stream_details.isNewStream) {
        if (lambdaEvents.checkIfDifferentFunctionTriggerAttached(stream_details.StreamArn, lambda_arn, credsId)) {
          error "Dynamodb stream contains a different function trigger already. Please remove the existing function trigger and try again."
        }
      } else {
        events.sendCompletedEvent('CREATE_ASSET', null, utilModule.generateAssetMap(config['provider'], stream_details.StreamArn, "dynamodb_stream", service_config), environment_logical_id);
      }
      lambdaEvents.updateDynamoDbResourceServerless(stream_details.StreamArn)
      deleteAndRedeployService(environment_logical_id, envBucketKey, accountDetails, service_config)
    } else {
      error "Error occured while accessing the dynamodb stream"
    }
  } else {
    echo "Exception occured while serverless deployment to ${environment_logical_id} environment : $deployOutput"
    error "Exception occured while serverless deployment to ${environment_logical_id} environment"
  }
}

def deleteAndRedeployService(environment_logical_id, envBucketKey, accountDetails, config){
  echoServerlessFile()
  def s3bucketvalue
  for (item in accountDetails.REGIONS) {
      if(item.REGION == config.region){
        s3bucketvalue = item.S3[envBucketKey]
      }
  }
  sh "serverless remove --stage $environment_logical_id -v --bucket ${s3bucketvalue}"
  def redeployOutput = servelessDeploy(environment_logical_id, envBucketKey)
  if (redeployOutput != 'success') {
    echo "Exception occured while serverless deployment to ${environment_logical_id} environment : $redeployOutput"
    error "Exception occured while serverless deployment to ${environment_logical_id} environment"
  }
}

def echoServerlessFile() {
  def serverlessyml = readFile('serverless.yml').trim()
  echo "serverless file data $serverlessyml"
}

def servelessDeploy(env, envBucketKey, credsId, env_key, accountDetails){
  def s3BucketNameValue;
  for (item in accountDetails.REGIONS) {
    if(item.REGION == service_config.region){
      s3BucketNameValue = item.S3[env_key]
    }
  }
  try {
    sh "serverless deploy --stage ${env} -v --bucket ${s3BucketNameValue} --profile ${credsId} > output.log"
    return "success"
  } catch (ex) {
    echo "Serverless deployment failed due to $ex"
    sh "cat output.log"
  }

  def outputLog = readFile('output.log').trim()
  echo "serverless deployment log $outputLog"
  return outputLog
}

def addEvents(def isScheduleEnabled, def isEc2EventEnabled, def isS3EventEnabled, def isSQSEventEnabled, def isStreamEnabled, def isDynamoDbEnabled) {
  echo "addEvents to serverless.yml file"
  def sedCommand = "s/eventsDisabled/events/g";
  if (!isScheduleEnabled) {
    sedCommand = sedCommand + "; /#Start:isScheduleEnabled/,/#End:isScheduleEnabled/d"
  }
  if (!isEc2EventEnabled) {
    sedCommand = sedCommand + "; /#Start:isEc2EventEnabled/,/#End:isEc2EventEnabled/d"
  }
  if (!isS3EventEnabled) {
    sedCommand = sedCommand + "; /#Start:isS3EventEnabled/,/#End:isS3EventEnabled/d"
    sedCommand = sedCommand + "; /#Start:isS3EventRoleEnabled/,/#End:isS3EventRoleEnabled/d"
  }
  if (!isSQSEventEnabled) {
    sedCommand = sedCommand + "; /#Start:isSQSEventEnabled/,/#End:isSQSEventEnabled/d"
  }
  if (!isStreamEnabled) {
    sedCommand = sedCommand + "; /#Start:isStreamEnabled/,/#End:isStreamEnabled/d"
  }
  if (!isDynamoDbEnabled) {
    sedCommand = sedCommand + "; /#Start:isDynamoDbEnabled/,/#End:isDynamoDbEnabled/d"
  }

  sh "sed -i -- '$sedCommand' ./serverless.yml"
  echoServerlessFile()
  echo "------------------------DONE--------------"
}

def removeEventResources(){
  sh "sed -i -- '/#Start:resources/,/#End:resources/d' ./serverless.yml"
  sh "sed -i -- '/#Start:events/,/#End:events/d' ./serverless.yml"
}


/**
 */
def isEnabled(config, key) {
  if (config.containsKey(key)) {
    return true
  } else {
    return false
  }
}

def LoadConfiguration() {
  def result = readFile('deployment-env.yml').trim()
  echo "result of yaml parsing....$result"
  def prop = [:]
  def resultList = result.tokenize("\n")

  // delete commented lines
  def cleanedList = []
  for (i in resultList) {
    if (i.toLowerCase().startsWith("#")) { } else {
      cleanedList.add(i)
    }
  }
  // echo "result of yaml parsing after clean up....$cleanedList"
  for (item in cleanedList) {
    // Clean up to avoid issues with more ":" in the values
    item = item.replaceAll(" ", "").replaceFirst(":", "#");
    def eachItemList = item.tokenize("#")
    //handle empty values
    def value = null;
    if (eachItemList[1]) {
      value = eachItemList[1].trim();
    }

    if (eachItemList[0]) {
      prop.put(eachItemList[0].trim(), value)
    }

  }
  echo "Loaded configurations....$prop"
  return prop
}

/**	Build project based on runtime
 */
def buildFunction(String runtime, String repo_name) {
  echo "installing dependencies for $runtime"
  if (runtime.indexOf("nodejs") > -1) {
		sh "npm install --save"
	} else if (runtime.indexOf("java") > -1) {
		sh "mvn package"
	} else if (runtime.indexOf("python") > -1) {
	  // install requirements.txt in library folder, these python modules will be a part of deployment package
		sh "rm -rf library"
		sh "mkdir library"
		sh "touch library/__init__.py"

    if (runtime == 'python3.6'){
      // Installing dependencies
      sh "pip3 install -r requirements.txt -t library"
      // create virtual environment and install pytest
      sh """
			python3 -m venv virtualenv
			. virtualenv/bin/activate
			pip3 install pytest
			pytest test
		  """
    } else {
      // Installing dependencies
      sh "pip install -r requirements.txt -t library"
      // create virtual environment and install pytest
		  sh """
		  pip install virtualenv
		  virtualenv venv
		  . venv/bin/activate
		  pip install pytest
	  	"""
    }
	} else if (runtime.indexOf("go") > -1 ) {
    // Installing dependencies using dep ensure
    // golang build scripts
   	withEnv(["GOPATH=${env.WORKSPACE}"]) {
      sh "mkdir -p $GOPATH/src"
      sh "rsync -a --exclude='.*' $GOPATH/" + repo_name + " $GOPATH/src"
      sh "cd $GOPATH/src/"+ repo_name+" && dep ensure"
      sh "cd $GOPATH/src/"+ repo_name+" && env GOOS=linux GOARCH=amd64 go build -o $GOPATH/"+ repo_name+"/main  *.go"
    }
  }
}

/** Reset credentials
 */
def resetCredentials(credsId) {
  echo "resetting AWS credentials"
  def credPath = System.getenv().HOME + "/.aws/credentials"
  def confPath = System.getenv().HOME + "/.aws/config"
  sh "sed -i '/${credsId}/,+2d' ${credPath}"
  sh "sed -i '/${credsId}/,+1d' ${confPath}"
}

/** Validate basic configurations in the deployment yaml file and error if any keys are
	missing.
*/
def validateDeploymentConfigurations(def prop) {
	if (prop.containsKey("service")) {
		if (prop['service'] == "") {
			error "Wrong configuration. Value for Key 'service' is missing in the configuration"
		}
	} else {
		error "Wrong configuration. Key 'service' is missing in the configuration"
	}
	if (prop.containsKey("providerRuntime")) {
		def _runtime = prop['providerRuntime']
		if (_runtime == "") {
			error "Wrong configuration. Value for Key 'providerRuntime' is missing in the configuration"
		} else {
			def validRuntimes = ["nodejs8.10", "nodejs10.x", "python3.6", "java8", "go1.x", "c#"]
			def flag = false

			for (int i = 0; i < validRuntimes.size(); i++) {
				if (_runtime == validRuntimes[i]) {
					flag = true
				}
			}

			if (!flag) {
				echo "$flag"
				error "Runtime given in the configuration is not valid."
			}
		}
	} else {
		error "Wrong configuration. Key 'providerRuntime' is missing in the configuration"
	}
	if (prop.containsKey("providerTimeout")) {
		if (prop['providerTimeout'] == "") {
			error "Wrong configuration. Value for Key 'providerTimeout' is missing in the configuration"
		} else if (Integer.parseInt(prop['providerTimeout']) > 300) { // Should not be a high
			error "Wrong configuration. Value for Key 'providerTimeout' should be a less than 160"
		}
	} else if (config['provider'] == "azure") {
    // we use azure default timeout
  } else {
		error "Wrong configuration. Key 'providerTimeout' is missing in the configuration"
	}

	if (prop.containsKey("region")) {
		if (prop['region'] == "") {
			error "Wrong configuration. Value for Key 'region' is missing in the configuration"
		}
	} else {
		error "Wrong configuration. Key 'region' is missing in the configuration"
	}

	def runtime = prop['providerRuntime']
	if (runtime.indexOf("java") > -1) {

		if (prop.containsKey("artifact")) {
			if (prop['artifact'] == "") {
				error "Wrong configuration. Value for Key 'artifact' is missing in the configuration"
			}
		} else {
			error "Wrong configuration. Key 'artifact' is missing in the configuration"
		}

		if (prop.containsKey("mainClass")) {
			if (prop['mainClass'] == "") {
				error "Wrong configuration. Value for Key 'mainClass' is missing in the configuration"
			}
		} else {
			error "Wrong configuration. Key 'mainClass' is missing in the configuration"
		}
	}
}

def loadServerlessConfig(String runtime, def isEventSchdld, def isScheduleEnabled, def isEc2EventEnabled, def isS3EventEnabled, def isSQSEventEnabled, def isStreamEnabled, def isDynamoDbEnabled) {

  def configPackURL = scmModule.getCoreRepoCloneUrl("serverless-config-pack")

  dir('_config') {
    checkout([$class: 'GitSCM', branches: [
      [name: '*/master']
    ], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [
        [credentialsId: repo_credential_id, url: configPackURL]
      ]])
  }

  echo "isEventSchdld: $isEventSchdld,isScheduleEnabled: $isScheduleEnabled, isEc2EventEnabled: $isEc2EventEnabled,  isS3EventEnabled: $isS3EventEnabled, isStreamEnabled: $isStreamEnabled, isDynamoDbEnabled: $isDynamoDbEnabled, isSQSEventEnabled: $isSQSEventEnabled"

  if (runtime.indexOf("nodejs") > -1) {
    sh "cp _config/serverless-nodejs.yml ./serverless.yml"
  } else if (runtime.indexOf("java") > -1) {
    sh "cp _config/serverless-java.yml ./serverless.yml"
  } else if (runtime.indexOf("python") > -1) {
    sh "cp _config/serverless-python.yml ./serverless.yml"
  } else if (runtime.indexOf("go") > -1){
    sh "cp _config/serverless-go.yml ./serverless.yml"
  }

  if (isEventSchdld == true) {
    addEvents(isScheduleEnabled, isEc2EventEnabled, isS3EventEnabled, isSQSEventEnabled, isStreamEnabled, isDynamoDbEnabled)
	}

	if (isS3EventEnabled || isSQSEventEnabled || isDynamoDbEnabled || isStreamEnabled) {
    sh "cp _config/aws-events-policies/custom-policy.yml ./policyFile.yml"
 	}

  if(!isEventSchdld) {
    removeEventResources()
  }

  echoServerlessFile()
}

def echoServiceInfo(String env) {
  try {
    echo "Deployment info:"
    sh "serverless --stage $env info -v > deploy-info.txt"

    def svc_response = ''
    def result = readFile('deploy-info.txt').trim()
    def resultList = result.tokenize("\n")

    for (item in resultList) {
      if (item.startsWith("HandlerLambdaFunctionQualifiedArn")) {
        def arn = item.trim().substring(35)
        version = arn.tokenize(':').last()
        arn = arn.substring(0, arn.length() - version.length() - 1)
        svc_response = "Function ARN: " + arn
      }
    }
    return svc_response
  } catch (Exception ex) {
    echo "Error while getting service info: " + ex.getMessage()
  }
}

/**
	Create the subscription filters and loggroup if not existing
**/
def createSubscriptionFilters(config, env_key, credsId, accountDetails) {
  def logGroupName = "${configLoader.INSTANCE_PREFIX}_${config['domain']}_${config['service']}_${environment_logical_id}"
  def lambda = "/aws/lambda/${logGroupName}"
  def logStreamer = configLoader.JAZZ.PLATFORM.AWS.KINESIS_LOGS_STREAM.PROD

  try {
    sh "aws logs create-log-group --log-group-name ${lambda} --profile ${credsId}"
  } catch (Exception ex) { } // ignore if already existing

  try {
    filter_json = sh(
      script: "aws logs describe-subscription-filters --output json --log-group-name \"${lambda}\"  --profile ${credsId}",
      returnStdout: true
    ).trim()
    echo "${filter_json}"
    def resultJson = parseJson(filter_json)
    filtername = resultJson.subscriptionFilters[0].filterName
    echo "removing existing filter... $filtername"
    if (filtername != "" && !filtername.equals(lambda)) {
      sh "aws logs delete-subscription-filter --output json --log-group-name \"${lambda}\" --filter-name \"${filtername}\"  --profile ${credsId}"
    }
  } catch (Exception ex) { } // ignore error if not created yet
  try {
    //updating the policy if the deployment account is not primary
    for (item in configLoader.AWS.ACCOUNTS) {
      if(item.ACCOUNTID == service_config.accountId){
        if(!item.PRIMARY){
          def destARN
          for (data in accountDetails.REGIONS) {
            if(data.REGION == service_config.region){
              destARN = data.LOGS.PROD
            }
          }
          sh "aws logs put-subscription-filter --output json --log-group-name \"${lambda}\" --filter-name \"${lambda}\" --filter-pattern \"\" --destination-arn \"${destARN}\"  --profile ${credsId}"
        } else {
          sh "aws logs put-subscription-filter --output json --log-group-name \"${lambda}\" --filter-name \"${lambda}\" --filter-pattern \"\" --destination-arn \"${logStreamer}\"  --role-arn ${accountDetails.IAM.PLATFORMSERVICES_ROLEID} --profile ${credsId}"
        }
      }
    }
  } catch (Exception ex) {
    echo "error occured: " + ex.getMessage()
  }
}

def writeServerlessFile(config, env, accountDetails) {

  def iamRoleArnValue;
  if(config['iamRoleARN'] != null && !config['iamRoleARN'].equals("")){
      iamRoleArnValue = config['iamRoleARN']
  } else {
      iamRoleArnValue = accountDetails.IAM.USERSERVICES_ROLEID;
  }

  sh "pwd"
  sh "sed -i -- 's/\${file(deployment-env.yml):service}/${configLoader.INSTANCE_PREFIX}-${config['domain']}-${config['service']}/g' serverless.yml"
  sh "sed -i -- 's/\${functionName}/${configLoader.INSTANCE_PREFIX}_${config['domain']}_${config['service']}_${env}/g' serverless.yml"
  sh "sed -i -- 's/{inst_stack_prefix}/${configLoader.INSTANCE_PREFIX}/g' serverless.yml"
  sh "sed -i -- 's/{env-stage}/${env}/g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):region}/${config['region']}/g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):domain, self:provider.domain}/${config['domain']}/g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):owner, self:provider.owner}/${config['created_by']}/g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):providerRuntime}/${config['providerRuntime']}/g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):providerMemorySize}/${config['providerMemorySize']}/g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):providerTimeout}/${config['providerTimeout']}/g' serverless.yml"
  sh "sed -i -- 's|\${file(deployment-env.yml):eventScheduleRate}|${config['eventScheduleRate']}|g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):eventScheduleEnable}/${config['eventScheduleEnable']}/g' serverless.yml"

  if ((config['service'] in configLoader.JAZZ.VPC_SERVICES.FUNCTIONS) && config['domain'] == 'jazz' && configLoader.JENKINS.DOCKERIZED == true) {
    addVpcDetails(config)
  }

  if (config['artifact']) {
    sh "sed -i -- 's/\${file(deployment-env.yml):artifact}/${config['artifact']}/g' serverless.yml"
  }

  if (config['mainClass']) {
    sh "sed -i -- 's/\${file(deployment-env.yml):mainClass}/${config['mainClass']}/g' serverless.yml"
  }

  if (config['event_source_s3']) {
    def event_source_s3 =  lambdaEvents.getEventResourceNamePerEnvironment(config['event_source_s3'], env, "-")
    def event_s3_arn = "arn:aws:s3:::${event_source_s3}"
    sh "sed -i -- 's/{event_source_s3}/${event_source_s3}/g' ./serverless.yml"
    sh "sed -i -- 's/{event_action_s3}/${config['event_action_s3']}/g' ./serverless.yml"
    sh "sed -i -- 's|{event_s3_arn}|${event_s3_arn}|g' policyFile.yml"
    sh "sed -i -- 's/resourcesDisabled/resources/g' ./serverless.yml"
  }

  if (config['event_source_sqs']) {
    def event_source_sqs = lambdaEvents.getSqsQueueName(config['event_source_sqs'], env)
    def event_sqs_arn = lambdaEvents.getEventResourceNamePerEnvironment(config['event_source_sqs'], env, "_")
    sh "sed -i -- 's/{event_source_sqs}/${event_source_sqs}/g' ./serverless.yml"
    sh "sed -i -- 's|{event_sqs_arn}|${event_sqs_arn}|g' ./serverless.yml"
    sh "sed -i -- 's|{event_sqs_arn}|${event_sqs_arn}|g' policyFile.yml"
    sh "sed -i -- 's/resourcesDisabled/resources/g' ./serverless.yml"
  }

  if (config['event_source_kinesis']) {
    def event_source_kinesis = lambdaEvents.splitAndGetResourceName(config['event_source_kinesis'], env)
    sh "sed -i -- 's/resourcesDisabled/resources/g' ./serverless.yml"
    sh "sed -i -- 's|{event_source_kinesis}|${event_source_kinesis}|g' ./serverless.yml"
  }

  if (config['event_source_dynamodb']) {
    def event_source_dynamodb = lambdaEvents.splitAndGetResourceName(config['event_source_dynamodb'], env)
    sh "sed -i -- 's/resourcesDisabled/resources/g' ./serverless.yml"
    sh "sed -i -- 's|{event_source_dynamodb}|${event_source_dynamodb}|g' serverless.yml"
  }

  if (config['event_source_dynamodb'] || config['event_source_sqs'] || config['event_source_kinesis'] || config['event_source_s3']) {
    sh "sed -i -e 's|\${file(deployment-env.yml):iamRoleARN}|customEventRole|g' serverless.yml"
  } else {
    sh "sed -i -e 's|\${file(deployment-env.yml):iamRoleARN}|${iamRoleArnValue}|g' serverless.yml"
  }

}

def addVpcDetails(config) {
  echo "addVpcdetails to serverless.yml file"
  sh "sed -i -- 's/vpcDisabled/vpc/g' ./serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):securityGroupIds}/${config['securityGroupIds']}/g' serverless.yml"
  sh "sed -i -- 's/\${file(deployment-env.yml):subnetIds}/${config['subnetIds'] }/g' serverless.yml"
}

/**
 * For getting token to access catalog APIs.
 * Must be a service account which has access to all services
 */
def setCredentials() {
  def loginUrl = g_base_url + '/jazz/login'
  def token

  withCredentials([
    [$class: 'UsernamePasswordMultiBinding', credentialsId: g_svc_admin_cred_ID, passwordVariable: 'PWD', usernameVariable: 'UNAME']
  ]) {
    echo "user name is $UNAME"

    def login_json = []

    login_json = [
      'username': UNAME,
      'password': PWD
    ]
    def tokenJson_token = null
    def payload = JsonOutput.toJson(login_json)

    try {
      token = sh(script: "curl --silent -X POST -k -v \
				-H \"Content-Type: application/json\" \
					$loginUrl \
				-d \'${payload}\'", returnStdout: true).trim()

      def tokenJson = parseJson(token)
      tokenJson_token = tokenJson.data.token

      return tokenJson_token
    } catch (e) {
      echo "error occured: " + e.getMessage()
      error "error occured: " + e.getMessage()
    }
  }
}

/**
 * Send email to the recipient with the build status and any additional text content
 * Supported build status values = STARTED, FAILED & COMPLETED
 * @return
 */
def send_status_email (build_status, email_content) {
  echo "Sending build notification to ${config['created_by']}"
	// TODO: Use this to make the notification look better?
	def body_html = ''
	def body_subject = "[Jazz Build Notification] Deployment ${build_status} for your service: ${config['service']}"
	def body_text =  'View the complete build log here: ' + env.BUILD_URL + 'console'
  	if (email_content != '') {
    	body_text = email_content + '\n\n' + body_text
	}
	body = JsonOutput.toJson([
		from: 'Jazz Admin <' + configLoader.JAZZ.STACK_ADMIN + '>',
		to: config['created_by'],
		subject: body_subject,
		text: body_text,
		bcc: configLoader.JAZZ.STACK_ADMIN,
		html: body_html
	])

	try {
		def sendMail = sh(script: "curl -X POST \
						${g_base_url}/jazz/email \
						-k -v -H \"Authorization: $auth_token\" \
						-H \"Content-Type: application/json\" \
						-d \'${body}\'", returnStdout: true).trim()
    	def responseJSON = parseJson(sendMail)
		if (responseJSON.data) {
			echo "successfully sent e-mail to ${config['created_by']}"
		} else {
			echo "exception occured while sending e-mail: $responseJSON"
		}
	} catch (e) {
    echo "Failed while sending build status notification: " + e.toString()
  }
}


/**
 *  Function to get arns of the triggers/events configured for the Lambda.
 *
 */
def getEventsArn(config, env, credsId) {
  def eventsArn = []
  try {
    def lambdaFnName = "${configLoader.INSTANCE_PREFIX}_${config['domain']}_${config['service']}_${env}"
    def lambdaPolicyTxt = sh(script: "aws lambda get-policy --region ${config['region']} --function-name $lambdaFnName --output json --profile ${credsId}", returnStdout: true)

    def policyLists = null
    if (lambdaPolicyTxt) {
      def lambdaPolicyJson = new groovy.json.JsonSlurperClassic()
      policyLists = lambdaPolicyJson.parseText(lambdaPolicyJson.parseText(lambdaPolicyTxt).Policy)
      if (policyLists) {
        for (st in policyLists.Statement) {
          if (st.Principal.Service == "events.amazonaws.com") {
            if (st.Condition.ArnLike["AWS:SourceArn"]) {
              eventsArn.push(st.Condition.ArnLike["AWS:SourceArn"])
            }
          }
        }
      }
    }
    return eventsArn
  } catch (ex) {
    // Skip the 'ResourceNotFoundException' when deploying first time. Workflow can't fail here.
    echo "Can't fetch the events policy configurations for lambda. " + ex.getMessage()
    return []
  }
}

def getLambdaARN(stackName, credsId) {
  def ARN = "";

  try {
    def cloudformation_resources = "";
    cloudformation_resources = sh(returnStdout: true, script: "aws cloudformation describe-stacks --output json --stack-name ${stackName} --profile ${credsId} --region ${service_config.region}")
    def parsedObject = parseJson(cloudformation_resources);
    def outputs = parsedObject.Stacks[0].Outputs;

    for (output in outputs) {
      if (output.OutputKey == "HandlerLambdaFunctionQualifiedArn") {
        ARN = output.OutputValue
      }
    }
  } catch (ex) {
    error ex.getMessage();
  }

  return ARN;
}

/** Run validation based on runtime
 */
def runValidation(String runtime) {
  echo "running validations for $runtime"
  if (runtime.indexOf("nodejs") > -1) {
    sh "jshint *.js"
  } else if (runtime.indexOf("java") > -1) {
    sh "java -cp ${configLoader.CODE_QUALITY.SONAR.CHECKSTYLE_LIB} com.puppycrawl.tools.checkstyle.Main -c sun_checks.xml src"
  } else if (runtime.indexOf("python") > -1) {
    // placeholder for adding runtime specific validations
  } else if (runtime.indexOf("go") > -1) {
    // placeholder for adding runtime specific validations
  }
}

@NonCPS
def parseJson(jsonString) {
  def lazyMap = new groovy.json.JsonSlurperClassic().parseText(jsonString)
  def m = [:]
  m.putAll(lazyMap)
  return m
}

def updatePlatformServiceTemplate(config, roleARN, current_environment, repo_name) {
  echo "loadServerlessConfig......."
  def jenkinsURL = JenkinsLocationConfiguration.get().getUrl().replaceAll("/", "\\\\/")
  serviceConfigdata.initialize(configLoader, roleARN, config['region'], config['accountId'], jenkinsURL, current_environment, repo_name, utilModule, awsAPIGatewayModule)
  serviceConfigdata.loadServiceConfigurationData()
}
/*
 * Load build modules
 */
def loadBuildModules(buildModuleUrl) {
  dir('build_modules') {
    checkout([$class: 'GitSCM', branches: [
      [name: '*/master']
    ], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [
        [credentialsId: repo_credential_id, url: buildModuleUrl]
      ]])

    configModule = load "config-loader.groovy"
		configLoader = configModule.loadConfigData(aws_credential_id, region, instance_prefix)
    echo "config loader loaded successfully."

    awsAPIGatewayModule = load "aws-apigateway-module.groovy"
    awsAPIGatewayModule.initialize()

    scmModule = load "scm-module.groovy"
    scmModule.initialize(configLoader)
    echo "SCM module loaded successfully."

    serviceConfigdata = load "service-configuration-data-loader.groovy"
    echo "Service configuration module loaded successfully."

    events = load "events-module.groovy"
    echo "Event module loaded successfully."

    serviceMetadataLoader = load "service-metadata-loader.groovy"
    serviceMetadataLoader.initialize(configLoader)
    echo "Service metadata loader module loaded successfully."

    utilModule = load "utility-loader.groovy"
    echo "Util module loaded successfully."

    lambdaEvents = load "aws-lambda-events-module.groovy"
    lambdaEvents.initialize(configLoader, utilModule)
    echo "Lambda event module loaded successfully."

    sonarModule = load "sonar-module.groovy"
    echo "Sonar module loaded successfully."

    environmentDeploymentMetadata = load "environment-deployment-metadata-loader.groovy"
    echo "Environment deployment data loader module loaded successfully."

    def resourceUtility = load "resource-utility.groovy"
    resourceUtility.initialize(configLoader)
    echo "resource util init successfully."

    def azureUtility = load "azure-utility.groovy"
    azureUtility.initialize(configLoader, resourceUtility, utilModule)
    echo "Azure util init successfully."
    azureDeployer = load "azure-function-deploy-module.groovy"
    azureDeployer.initialize(configLoader, utilModule, scmModule, events, azureUtility)
    echo "Azure deploy module init successfully."

  }
}

def getBuildModuleUrl() {
  if (scm_type && scm_type != "bitbucket") {
    // right now only bitbucket has this additional tag scm in its git clone path
    return "http://${repo_base}/${repo_core}/jazz-build-module.git"
  } else {
    return "http://${repo_base}/scm/${repo_core}/jazz-build-module.git"
  }
}

def handleDeploymentErrors(deployOutput, envBucketKey, env, credsId, accountDetails, config) {
  def rollbackErrorMessage = "ROLLBACK_COMPLETE state and can not be updated"
  def logGroupErrorMessage = "CloudFormation - CREATE_FAILED - AWS::Logs::LogGroup - HandlerLogGroup"
	if(deployOutput.contains(rollbackErrorMessage)){
		deleteAndRedeployService(env, envBucketKey, accountDetails, config)
	}
	else if (deployOutput.contains(logGroupErrorMessage))
	{
		def lambda = "/aws/lambda/${envBucketKey}-${env}"
		if (isExistingLogGroup(lambda, credsId)){
			removeLogGroup(lambda, credsId)
			deleteAndRedeployService(env, envBucketKey, accountDetails, config);
		} else {
			error "Unable to find existing log groups"
		}
	}
	else {
			error "Exception occured while serverless deployment to ${env} environment"
	}
}

def isExistingLogGroup (groupName, credsId){
	def isExistingLogGrp = false
	def filterLogs = sh (
		script: "aws logs describe-log-groups --log-group-name-prefix $groupName --output json --profile ${credsId}",
		returnStdout: true
	).trim()
	def toJSON = new groovy.json.JsonSlurper()
	def filterLogsJSON = toJSON.parseText(filterLogs)
	def logGroups = filterLogsJSON.logGroups
	if(logGroups.size() > 0  && logGroups[0].logGroupName == groupName){
		isExistingLogGrp = true
	}
	return isExistingLogGrp
}

def removeLogGroup(groupName, credsId) {
	echo "Removing log group $groupName"
	sh "aws logs delete-log-group --log-group-name $groupName --profile ${credsId}"
	echo "successfully removed log group $groupName"
}
